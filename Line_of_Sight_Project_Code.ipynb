{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Author: Cindy Y.Liu, Tengfei Zheng\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "%pylab inline\n",
    "import math\n",
    "import csv\n",
    "import shapefile\n",
    "\n",
    "my_folder = '/Users/cindyliu/Documents/Line of Sight_Materials/All Deliverables' # file path substituted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the detections' pixel files for each plume type from the all inclusive data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output folder\n",
    "file_path_1 = '{0}/Pixel Files/All'.format(my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the plume types    \n",
    "plume_type = ['Ammonia','Carbon Dioxide','Difluoromethane','Cholorodifluoromethane','Tetrafluoroethane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the x pixel of westside2 and westside3 images\n",
    "def adjust_x_pixel(df):\n",
    "    # create a column to store the adjusted x pixel for the detections in westside2 and 3\n",
    "    df['Detection pixel x_adjusted']=\"\"\n",
    "    for index,row in df.iterrows():\n",
    "        if \"Westside2\" in row.Cube:\n",
    "            df.loc[index,'Detection pixel x_adjusted'] = df.loc[index,'Detection pixel x'] + 650\n",
    "        elif \"Westside3\" in row.Cube:\n",
    "            df.loc[index,'Detection pixel x_adjusted'] = df.loc[index,'Detection pixel x'] + 1400\n",
    "        else:\n",
    "            df.loc[index,'Detection pixel x_adjusted'] = df.loc[index,'Detection pixel x']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_detections_pixel(plume_name):\n",
    "    df = pd.read_csv('AllDays_Top8agents.csv')\n",
    "    # determine the y pixel range in which detections are kept\n",
    "    y_pixel_lower_limit = 15\n",
    "    y_pixel_upper_limit = 100\n",
    "    # filter out those detections which have vertical positions higher and lower than buildings\n",
    "    df = df[(df['Detection pixel y']>y_pixel_lower_limit) & (df['Detection pixel y']<y_pixel_upper_limit)]\n",
    "    # filter out those detections which are not in the range of Westside1,2,3\n",
    "    df = df[df['Cube'].str.contains('Westside1|Westside2|Westside3', na=False)]\n",
    "    # subset the detections of the input plume\n",
    "    df = df[df['ID'].str.contains(plume_name, na=False)]\n",
    "    # adjust_x_pixel\n",
    "    df = adjust_x_pixel(df)\n",
    "    # export to csv file \n",
    "    df.to_csv('{0}/{1}_All_Pixels.csv'.format(file_path_1,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    get_all_detections_pixel(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the detections' pixel files for a specific plume on a given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a specific day\n",
    "which_date = '12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_one_day_detections_pixel(plume_name,which_date):\n",
    "    df = pd.read_csv(('{0}/{1}_All_Pixels.csv'.format(file_path_1,plume_name)))\n",
    "    # subset the detections of a specific date\n",
    "    date_format = '4/'+ which_date + '/15'\n",
    "    df = df[df['NY Time'].str.contains(date_format, na=False)]\n",
    "    # export to csv file \n",
    "    df.to_csv('{0}/201504{1}/{2}_All_Pixels.csv'.format(file_path_1,which_date,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    get_one_day_detections_pixel(i,which_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Obtain the longitude and latitude information of the range of detections'  based on their pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output folder\n",
    "file_path_2 = '{0}/Point Files/All'.format(my_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get \n",
    "x0,y0 =  -74.025852,40.744314\n",
    "xn,yn =  -73.983227,40.769178\n",
    "xs,ys =  -74.017737,40.705468\n",
    "k1 = (yn-y0)/(xn-x0)\n",
    "k2 = (ys-y0)/(xs-x0)\n",
    "theta1 = math.atan(k1)\n",
    "theta2 = math.atan(k2)\n",
    "theta_all = theta1-theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pixel to lat,lon transfer\n",
    "def transfer_to_lon_lat(detections_pixel_range):\n",
    "    detections_pixel_range['theta'] = theta_all*(1941 - detections_pixel_range['Detection Pixel x_adjusted'])/(1941-2)\n",
    "    detections_pixel_range['k'] = (tan(detections_pixel_range['theta'])+k2)/(1- tan(detections_pixel_range['theta'])*k2)\n",
    "    detections_pixel_range['b'] = y0 - x0*detections_pixel_range['k']\n",
    "    detections_pixel_range['Lon_End'] = -73.93  # choose an arbitrary longtitude end for the line of sight\n",
    "    detections_pixel_range['Lat_End'] = detections_pixel_range['k']*detections_pixel_range['Lon_End']  + detections_pixel_range['b']\n",
    "    return detections_pixel_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if only need transfer pixels on a specific date, change the file path to the specific date folder\n",
    "file_path_1 = '{0}/Pixel Files/All/201504{1}'.format(my_folder,which_date)\n",
    "file_path_2 = '{0}/Point Files/All/201504{1}'.format(my_folder,which_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get longitude and latitude information of detections\n",
    "def get_lon_lat(plume_name):\n",
    "    dm = pd.read_csv('{0}/{1}_All_Pixels.csv'.format(file_path_1,plume_name))\n",
    "    # get the two boundaries' pixel information for detections\n",
    "    dm['range_side_1'] = dm['Detection pixel x_adjusted'] - dm['Pixels']/2\n",
    "    dm['range_side_2'] = dm['Detection pixel x_adjusted'] + dm['Pixels']/2\n",
    "    range_side_1 = dm['range_side_1'].tolist()\n",
    "    range_side_2 = dm['range_side_2'].tolist()\n",
    "    # extract detection index information\n",
    "    detection_index = dm['Unnamed: 0']\n",
    "    detection_index_double_list = []\n",
    "    for j in detection_index:\n",
    "        detection_index_double_list.append(j)\n",
    "        detection_index_double_list.append(j)\n",
    "    # extract time information\n",
    "    NY_Time_list = dm['NY Time']\n",
    "    NY_Time_double_list = []\n",
    "    for i in NY_Time_list:\n",
    "        NY_Time_double_list.append(i)\n",
    "        NY_Time_double_list.append(i)\n",
    "    # extract x pixel information\n",
    "    pixel_x_list=[]\n",
    "    for i in range(len(range_side_1)):\n",
    "        pixel_x_list.append(range_side_1[i])\n",
    "        pixel_x_list.append(range_side_2[i])\n",
    "    # create a dataframe to store all the information together\n",
    "    detections_pixel_range = pd.DataFrame({'Detection Index':detection_index_double_list,'NY Time':NY_Time_double_list,\\\n",
    "                                          'Detection Pixel x_adjusted':pixel_x_list})\n",
    "    # transfer to longitude and latitude from pixel\n",
    "    detections_pixel_range = transfer_to_lon_lat(detections_pixel_range)\n",
    "    # export to csv file\n",
    "    detections_pixel_range.to_csv('{0}/{1}_All_Lon_Lat.csv'.format(file_path_2,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    get_lon_lat(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the longitude and latitude information of plume source detected manually on a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a specific day\n",
    "which_date = '12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "file_path_4 = '{0}/Pixel Files/Source'.format(my_folder)\n",
    "file_path_5 = '{0}/Point Files/Source'.format(my_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pixel to lat,lon transfer\n",
    "def source_transfer_to_lon_lat(detections_pixel_range):\n",
    "    detections_pixel_range['theta'] = theta_all*(1941 - detections_pixel_range['Detection Pixel x'])/(1941-2)\n",
    "    detections_pixel_range['k'] = (tan(detections_pixel_range['theta'])+k2)/(1- tan(detections_pixel_range['theta'])*k2)\n",
    "    detections_pixel_range['b'] = y0 - x0*detections_pixel_range['k']\n",
    "    detections_pixel_range['Lon_End'] = -73.93  # choose an arbitrary longtitude end for the line of sight\n",
    "    detections_pixel_range['Lat_End'] = detections_pixel_range['k']*detections_pixel_range['Lon_End']  + detections_pixel_range['b']\n",
    "    return detections_pixel_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_get_lon_lat(plume_name):\n",
    "    if plume_name == 'Carbon Dioxide':\n",
    "        plume_name = \"Carbon_Dioxide\"\n",
    "    dm = pd.read_csv('{0}/{1}/{2}_Source_Pixels_1504{3}.csv'.format(file_path_4,plume_name,plume_name,which_date))\n",
    "    # extract x pixel information\n",
    "    pixel_x_list = dm['Detection pixel x']\n",
    "    # create a dataframe to store all the information together\n",
    "    detections_pixel_range = pd.DataFrame({'Detection Pixel x':pixel_x_list})\n",
    "    # transfer to longitude and latitude from pixel\n",
    "    detections_pixel_range = source_transfer_to_lon_lat(detections_pixel_range)\n",
    "    # export to csv file\n",
    "    detections_pixel_range.to_csv('{0}/201504{1}/{2}_All_Lon_Lat.csv'.format(file_path_5,which_date,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    source_get_lon_lat(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate buffer polygon files from detections' range lon/lat information files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output file path\n",
    "file_path_3 = '{0}/Polygon Files/All'.format(my_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Steven Institute of Technology Observation Point\n",
    "X0 = -74.0239\n",
    "Y0 = 40.7449 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if only need polygon files a specific date, change the file path to the specific date folder\n",
    "file_path_3 = '{0}/Polygon Files/All/201504{1}'.format(my_folder,which_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a list of polygon points for generating the polygon shapefile\n",
    "def get_polygon_points(plume_name):\n",
    "    dm = pd.read_csv('{0}/{1}_All_Lon_Lat.csv'.format(file_path_2,plume_name))  #input files\n",
    "    # change NY time to timestamp format\n",
    "    dm['NY Time'] = pd.to_datetime(dm['NY Time'])\n",
    "    # new lists for the ending points' lontitude and latitude\n",
    "    X = dm['Lon_End'].tolist()\n",
    "    Y = dm['Lat_End'].tolist()\n",
    "    # new list for NY timestamp\n",
    "    d_time = dm['NY Time'].tolist()\n",
    "    list_of_time = []\n",
    "    for i in range(len(d_time)/2):\n",
    "        list_of_time.append(d_time[2*i])\n",
    "    # connect the observation points to the two ending points to create three-sided polygon\n",
    "    list_of_points = []\n",
    "    for i in np.arange(0,dm.shape[0],2):\n",
    "        points = [[X0,Y0]]\n",
    "        point_one = []\n",
    "        point_one.append(X[i])\n",
    "        point_one.append(Y[i])\n",
    "        point_two = []\n",
    "        point_two.append(X[i+1])\n",
    "        point_two.append(Y[i+1]) \n",
    "        points.append(point_one)\n",
    "        points.append(point_two)\n",
    "        list_of_points.append(points)\n",
    "    return plume_name,list_of_points,list_of_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_polygon_shapefile(plume_name,list_of_points,list_of_time):  \n",
    "    w = shapefile.Writer(shapefile.POLYGON)\n",
    "    for i in range(0,len(list_of_points)):\n",
    "        w.poly(parts = [list_of_points[i]])\n",
    "    w.field('FIRST_FLD','C','40')\n",
    "    w.field('NY_Time','C','40')\n",
    "    for j in range(0,len(list_of_time)):\n",
    "        w.record('First',list_of_time[j])\n",
    "    w.save('{0}/{1}/{2}'.format(file_path_3,plume_name,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    p,o,t = get_polygon_points(i)\n",
    "    get_polygon_shapefile(p,o,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate buffer polygon files from source detections' lon/lat information files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output folder\n",
    "file_path_6 = '{0}/Polygon Files/Source'.format(my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of polygon points for generating the polygon shapefile\n",
    "def source_get_polygon_points(plume_name):\n",
    "    if plume_name == 'Carbon Dioxide':\n",
    "        plume_name = \"Carbon_Dioxide\"\n",
    "    dm = pd.read_csv('{0}/201504{1}/{2}_All_Lon_Lat.csv'.format(file_path_5,which_date,plume_name))\n",
    "    # new lists for the ending points' lontitude and latitude\n",
    "    X = dm['Lon_End'].tolist()\n",
    "    Y = dm['Lat_End'].tolist()\n",
    "    # connect the observation points to the two ending points to create three-sided polygon\n",
    "    list_of_points = []\n",
    "    for i in np.arange(0,dm.shape[0],2):\n",
    "        points = [[X0,Y0]]\n",
    "        point_one = []\n",
    "        point_one.append(X[i])\n",
    "        point_one.append(Y[i])\n",
    "        point_two = []\n",
    "        point_two.append(X[i+1])\n",
    "        point_two.append(Y[i+1]) \n",
    "        points.append(point_one)\n",
    "        points.append(point_two)\n",
    "        list_of_points.append(points)\n",
    "    return plume_name,list_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_get_polygon_shapefile(plume_name,list_of_points):  \n",
    "    w = shapefile.Writer(shapefile.POLYGON)\n",
    "    for i in range(0,len(list_of_points)):\n",
    "        w.poly(parts = [list_of_points[i]])\n",
    "    w.field('FIRST_FLD','C','40')\n",
    "    for j in range(0,len(list_of_points)):\n",
    "        w.record('First','Polygon')\n",
    "    w.save('{0}/201504{1}/{2}/{3}'.format(file_path_6,which_date,plume_name,plume_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in plume_type:\n",
    "    p,o = source_get_polygon_points(i)\n",
    "    source_get_polygon_shapefile(p,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
